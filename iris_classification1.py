# -*- coding: utf-8 -*-
"""Iris Classification1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ldiZ8Bz8debsMyXx4FwY45A_xATXr8KR
"""

# prompt: Write the code to import necessary libraries for a classification project of the iris dataset classification

!pip install pandas
!pip install scikit-learn
!pip install matplotlib
#!pip install --upgrade scikit-learn

# prompt: Now write the import statements

import pandas as pd
import sklearn as sk
import matplotlib.pyplot as plt

"""##Data collection"""

# Import the necessary modules
from sklearn.datasets import load_iris
import pandas as pd

# Load the iris dataset
iris = load_iris()

# Create a dataframe from the data
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)

# Add a column for the species
iris_df['species'] = iris.target

# Print the dataframe
print(iris_df)

iris_df

"""##Exploratory data analysis"""

iris_df.isnull().sum()

# **3. Checking the descriptive statistics of the data:**

iris_df.describe()

# **2. Checking the data types of each column:**

iris_df.dtypes

# **4. Checking the distribution of each feature:**

for col in iris_df.columns[0:4]:
  plt.hist(iris_df[col], bins=10)
  plt.xlabel(col)
  plt.ylabel("Frequency")
  plt.title(f"Distribution of {col}")
  plt.show()

# **3. Bar plot:**

species_counts = iris_df["species"].value_counts()
plt.bar(species_counts.index, species_counts.values)
plt.xlabel("Species")
plt.ylabel("Count")
plt.title("Bar Plot of Species Counts")
plt.show()

"""##Data pre processing"""

from sklearn.preprocessing import LabelEncoder, StandardScaler

# Label encode the "species" column
label_encoder = LabelEncoder()
iris_df["species"] = label_encoder.fit_transform(iris_df["species"])

# Standardize the other columns
scaler = StandardScaler()
iris_df[iris_df.columns[0:4]] = scaler.fit_transform(iris_df[iris_df.columns[0:4]])

iris_df

# Split the data into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(iris_df[iris_df.columns[0:4]], iris_df["species"], test_size=0.2)

"""##Model Training"""

def print_board(board):
    for row in board:
        print(" | ".join(row))
        print("-" * 5)

def check_winner(board):
    # Check rows
    for row in board:
        if row.count(row[0]) == len(row) and row[0] != ' ':
            return True

    # Check columns
    for col in range(len(board)):
        if board[0][col] == board[1][col] == board[2][col] and board[0][col] != ' ':
            return True

    # Check diagonals
    if board[0][0] == board[1][1] == board[2][2] and board[0][0] != ' ':
        return True
    if board[0][2] == board[1][1] == board[2][0] and board[0][2] != ' ':
        return True

    return False

def tic_tac_toe():
    board = [[' ' for _ in range(3)] for _ in range(3)]
    player = 'X'
    print("Welcome to Tic-Tac-Toe!")

    while True:
        print_board(board)
        row = int(input("Enter row number (0, 1, or 2): "))
        col = int(input("Enter column number (0, 1, or 2): "))

        if row < 0 or row > 2 or col < 0 or col > 2:
            print("Invalid input! Please enter row and column numbers between 0 and 2.")
            continue

        if board[row][col] != ' ':
            print("That spot is already taken! Try again.")
            continue

        board[row][col] = player

        if check_winner(board):
            print_board(board)
            print(f"Player {player} wins!")
            break

        if all(all(cell != ' ' for cell in row) for row in board):
            print_board(board)
            print("It's a tie!")
            break

        player = 'O' if player == 'X' else 'X'

if __name__ == "__main__":
    tic_tac_toe()

def print_board(board):
    for row in board:
        print(" | ".join(row))
        print("-" * 5)

def check_winner(board):
    # Check rows
    for row in board:
        if row.count(row[0]) == len(row) and row[0] != ' ':
            return True

    # Check columns
    for col in range(len(board)):
        if board[0][col] == board[1][col] == board[2][col] and board[0][col] != ' ':
            return True

    # Check diagonals
    if board[0][0] == board[1][1] == board[2][2] and board[0][0] != ' ':
        return True
    if board[0][2] == board[1][1] == board[2][0] and board[0][2] != ' ':
        return True

    return False

def tic_tac_toe():
    board = [[' ' for _ in range(3)] for _ in range(3)]
    player = 'X'
    print("Welcome to Tic-Tac-Toe!")

    while True:
        print_board(board)
        row = int(input("Enter row number (0, 1, or 2): "))
        col = int(input("Enter column number (0, 1, or 2): "))

        if row < 0 or row > 2 or col < 0 or col > 2:
            print("Invalid input! Please enter row and column numbers between 0 and 2.")
            continue

        if board[row][col] != ' ':
            print("That spot is already taken! Try again.")
            continue

        board[row][col] = player

        if check_winner(board):
            print_board(board)
            print(f"Player {player} wins!")
            break

        if all(all(cell != ' ' for cell in row) for row in board):
            print_board(board)
            print("It's a tie!")
            break

        player = 'O' if player == 'X' else 'X'

if __name__ == "__main__":
    tic_tac_toe()

# Train the Decision Tree model
from sklearn.tree import DecisionTreeClassifier
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)

"""##Model evaluation"""

# Evaluate the model on the testing set
from sklearn.metrics import accuracy_score
predictions = decision_tree.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print("Accuracy:", accuracy)

from sklearn.metrics import classification_report, confusion_matrix

# Generate the classification report
classification_report = classification_report(y_test, predictions)
print("Classification Report:\n", classification_report)

import seaborn as sns
# Generate the confusion matrix
confusion_matrix = confusion_matrix(y_test, predictions)

# Visualize the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

import joblib

# Save the trained model to a file
joblib.dump(decision_tree, 'iris_model.joblib')

!pip install -q streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import joblib
# 
# # Set the title and header of the application
# st.title("Iris Flower Classification")
# st.header("Please fill in the features of the Iris flower:")
# 
# # Load the trained model outside the main function
# model = joblib.load('iris_model.joblib')
# 
# # Use a single form for user input and prediction
# with st.form("iris_form"):
#     # Add input fields for each feature
#     sepal_length = st.number_input("Sepal Length (cm):", min_value=0.0, max_value=10.0, step=0.1)
#     sepal_width = st.number_input("Sepal Width (cm):", min_value=0.0, max_value=10.0, step=0.1)
#     petal_length = st.number_input("Petal Length (cm):", min_value=0.0, max_value=10.0, step=0.1)
#     petal_width = st.number_input("Petal Width (cm):", min_value=0.0, max_value=10.0, step=0.1)
# 
#     # Display a submit button
#     submitted = st.form_submit_button("Classify")
# 
# # Define a function to handle prediction
# def output():
#     if submitted:
#         # Make a prediction using the loaded model
#         input_data = [sepal_length, sepal_width, petal_length, petal_width]
#         prediction = model.predict([input_data])
# 
#         # Display the prediction
#         st.write("Predicted Class:", prediction[0])
# 
# # Call the output function
# output()
# 
#

!npm install localtunnel

!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
from tensorflow import keras as kr
import matplotlib.pyplot as plt
# %matplotlib inline

(x_train,y_train),(x_test,y_test)=kr.datasets.mnist.load_data()

len(x_train)
len(x_test)
x_train[0].shape
plt.matshow(x_train(x_train[0]))#The matshow() function in matplotlib is used to
                                #display an array as a matrix in a new figure window.

# Normalizing the datasheet
x_train = x_train/255
x_test = x_test/255

# Flatting the datasheet in order
# to compute for model building
x_train_flatten = x_train.reshape(len(x_train), 28*28)
x_test_flatten = x_test.reshape(len(x_test), 28*28)

#select an image from the text datasets
image_index = 1 #you can change trhis index to view diffrent images

#display the selected image
plt.imshow(x_test[image_index],cmap='Blues')
plt.show()

#perform prediction on the selected image
prediction = model.predict(x_test_flatten[image_index].reshape(1,784))

#print the predicted label
predict_label = np.argmax(prediction)
print("predicted label for the selected image: {predicted_label}")

from openai import openai

api_key="sk."

pip install openai

from openai import OpenAI

client = OpenAI(
    # defaults to os.environ.get("OPENAI_API_KEY")
    api_key="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",
)

def chat_gpt(prompt):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )

    return response.choices[0].message.content.strip()

if __name__ == "__main__":
    while True:
        user_input = input("You: ")
        if user_input.lower() in ["quit", "exit", "bye"]:
            break

        response = chat_gpt(user_input)  # Fixed function name here
        print("chatbot:", response)

# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Create a dataframe with heart rate and age data
df = pd.DataFrame({"heart_rate": [72, 75, 78, 81, 84, 87, 90, 93, 96, 99],
                   "age": [20, 25, 30, 35, 40, 45, 50, 55, 60, 65]})

# Plot a scatter plot with a regression line
sns.regplot(x="age", y="heart_rate", data=df)
plt.xlabel("Age (in years)")
plt.ylabel("Heart Rate (in beats per minute)")
plt.title("Linear Regression Analysis of Heart Rate and Age")
plt.show()

# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Create a dataframe with income and happiness data
df = pd.DataFrame({"income": [15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75],
                   "happiness": [3, 4, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10]})

# Plot a scatter plot with a regression line
sns.regplot(x="income", y="happiness", data=df)
plt.xlabel("Income (in thousands)")
plt.ylabel("Happiness (scale from 1 to 10)")
plt.title("Regression Analysis Graph")
plt.show()

import pandas as pd
df = pd.read_csv("https://raw.githubusercontent.com/kb22/Heart-Disease-Prediction/master/dataset.csv")
df

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Complete the DataFrame
data = pd.DataFrame({
    'index': [0, 1, 2, 3, 4, 5, ...],  # add the rest of your 'index' values here
    'age': [63, 37, 41, 56, 57, ...],  # add the rest of your 'age' values here
    'chol': [233, 250, 204, 236, 354, ...],  # add the rest of your 'chol' values here
    # add the rest of your columns here
})

# Perform linear regression
X = data[['age']]  # independent variable
y = data['chol']  # dependent variable
reg = LinearRegression().fit(X, y)

# Plot the results
sns.regplot(x='age', y='chol', data=data)
plt.show()

pip install pandas

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Assuming 'data' is your DataFrame
data = pd.DataFrame({
    'index': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, ...

pip install pandas seaborn

import pandas as pd
df=pd.read_csv("https://raw.githubusercontent.com/kb22/Heart-Disease-Prediction/master/dataset.csv")
df
#SEPARATE THE Y FROM X
Y=df["target"]
Y
#SEPARATE THE X FROM Y
X=df.drop("target",axis=1)  #axis = 0 refers to horizontal axis or rows and axis = 1 refers to vertical axis or columns

#HERE THE TRAINING SET IS USED TO FIT OUR MODEL AND THE TESTING SET IS USED TO MAKE PREDICTIONS
from sklearn.model_selection  import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=100)

X_train
X_test
import pandas as pd
df=pd.read_csv("https://raw.githubusercontent.com/kb22/Heart-Disease-Prediction/master/dataset.csv")
df
#SEPARATE THE Y FROM X
Y=df["target"]
Y
#SEPARATE THE X FROM Y
X=df.drop("target",axis=1)  #axis = 0 refers to horizontal axis or rows and axis = 1 refers to vertical axis or columns

#HERE THE TRAINING SET IS USED TO FIT OUR MODEL AND THE TESTING SET IS USED TO MAKE PREDICTIONS
from sklearn.model_selection  import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=100)

X_train
X_test
Y_train
Y_test
#Linear regression analysis is used to predict the value of a variable based on the value of another variable
from sklearn.linear_model import LinearRegression  #=>training set is used to build a model
                                                   #=>testing set is used to serve as an unknown data which in you wanna test training set
lr=LinearRegression()
lr.fit(X_train,Y_train)#we wanna train the empty linear regression model on the following dataset namely x_train and y_train
Y_lr_train_pred=lr.predict(X_train) #HERE I'M BASICALLY MAKING A PREDICTION ON X_train
Y_lr_test_pred=lr.predict(X_test)   #HERE I'M BASICALLY MAKING A PREDICTION ON x_test
Y_lr_train_pred
Y_lr_test_pred
from sklearn.metrics import mean_squared_error,r2_score #mean_squared_error=>pins the mean square error
                                                        #how well the model predicts the outcome of the dependent variable
lr_train_mse=mean_squared_error(Y_train,Y_lr_train_pred)
lr_train_r2=r2_score(Y_train,Y_lr_train_pred)

lr_test_mse=mean_squared_error(Y_test,Y_lr_test_pred)
lr_test_r2=r2_score(Y_test,Y_lr_test_pred)

print("LR MSE(TRAIN)",lr_train_mse)
print("LR R2(TRAIN)",lr_train_r2)
print("LR MSE(TEST)",lr_test_mse)
print("LR R2(TEST)",lr_test_r2)
#to tidy this layout a bit more we use DataFrame=>gives us a tablular form with rows and columns
lr_results=pd.DataFrame(["Linear Regression",lr_train_mse,lr_train_r2,lr_test_mse,lr_test_r2]).transpose()
lr_results
#in order to give names for our columns
lr_results.columns=["Method","Training MSE","Training R2","Test MSE","Test R2"]
lr_results
#Random Forest=> Combines the output of multiple decision trees to reach a single result
#Ensemble methods =>Techniques that aim at improving the accuracy of results in models
# by combining multiple models instead of using a single model.
from sklearn.ensemble import RandomForestRegressor # #here we use regressor cause we are building regression
                                                   #models as our y (logS) is quantitative
rf=RandomForestRegressor(max_depth=2,random_state=100)
rf.fit(X_train,Y_train)
Y_rf_train_pred=rf.predict(X_train)
Y_rf_test_pred=rf.predict(X_test)
from sklearn.metrics import mean_squared_error,r2_score
rf_train_mse=mean_squared_error(Y_train,Y_rf_train_pred)
rf_train_r2=r2_score(Y_train,Y_rf_train_pred)

rf_test_mse=mean_squared_error(Y_test,Y_rf_test_pred)
rf_test_r2=r2_score(Y_test,Y_rf_test_pred)

print("RF MSE(TRAIN)",rf_train_mse)
print("RF R2(TRAIN)",rf_train_r2)
print("RF MSE(TEST)",rf_test_mse)
print("RF R2(TEST)",rf_test_r2)
#to tidy this up a bit more
rf_results=pd.DataFrame(["Random forest",rf_train_mse,rf_train_r2,rf_test_mse,rf_test_r2]).transpose()
rf_results
#In order to give names for our columns
rf_results.columns=["Method","Training MSE","Training R2","Testing MSE","Testing R2"]
rf_results
#TO CONCATINATE THE MODEL EVALUATION OF LINEAR REGRESSION AND RANDOM FOREST TOGETHER
df_models=pd.concat([lr_results,rf_results],axis=0) #axis 0 will will club data vertically
df_models
#drop=True => It does not add the current row index as a new column in DataFrame.
df_models.reset_index(drop=True)
import matplotlib.pyplot as plt   #for plotting graphically

plt.scatter(x=Y_train,y=Y_lr_train_pred)
plt.plot()
import matplotlib.pyplot as plt   #for plotting graphically
import numpy as np   #this si to get the trend line

plt.figure(figsize=(5,5))

import matplotlib.pyplot as plt

plt.figure(figsize=(5,5))
plt.scatter(Y_train, Y_lr_train_pred)
plt.plot([min(Y_train), max(Y_train)], [min(Y_train), max(Y_train)], color='red') # This line will create a diagonal line for reference
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted values for Linear Regression model')
plt.show()